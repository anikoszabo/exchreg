\newcommand{\NWtarget}[2]{#2}
\newcommand{\NWlink}[2]{#2}
\newcommand{\NWtxtMacroDefBy}{Fragment defined by}
\newcommand{\NWtxtMacroRefIn}{Fragment referenced in}
\newcommand{\NWtxtMacroNoRef}{Fragment never referenced}
\newcommand{\NWtxtDefBy}{Defined by}
\newcommand{\NWtxtRefIn}{Referenced in}
\newcommand{\NWtxtNoRef}{Not referenced}
\newcommand{\NWtxtFileDefBy}{File defined by}
\newcommand{\NWtxtIdentsUsed}{Uses:}
\newcommand{\NWtxtIdentsNotUsed}{Never used}
\newcommand{\NWtxtIdentsDefed}{Defines:}
\newcommand{\NWsep}{${\diamond}$}
\newcommand{\NWnotglobal}{(not defined globally)}
\newcommand{\NWuseHyperlinks}{}
\documentclass[reqno]{amsart}
\usepackage[margin=1in]{geometry}
\usepackage[colorlinks=true,linkcolor=blue]{hyperref}
\renewcommand{\NWtarget}[2]{\hypertarget{#1}{#2}}
\renewcommand{\NWlink}[2]{\hyperlink{#1}{#2}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bq}{\mathbf{q}}
\newcommand{\bpi}{\text{\boldmath $\pi$}}
\newcommand{\leqst}{\mathrel{\preceq^{st}}}
\newcommand{\geqst}{\mathrel{\succeq^{st}}}

\title{Semi-parametric relative risk model for correlated binary data}
\author{Aniko Szabo}
\date{\today}


\begin{document}
\maketitle

Based on the exchangeability and marginal compatibility assumptions, we propose the following semi-parametric model to describe  $\lambda_k(z), k=0,\ldots, N$ as a function of covariates $z$:
\begin{equation}\label{E:semipara}
	\lambda_k(z) = {\mu_k} \times {\theta(\beta' z)^k}, k = 0, \dots, N,
\end{equation}
where $\theta(\beta' z)$ is a known function with range $[0,1]$; and $\mu_k$ is a non-parametric baseline vector of joint probabilities.

Since $\lambda_1$ equals the marginal probability of a response $\pi$, model \eqref{E:semipara} can be interpreted as a multiplicative model for it:
\begin{equation*}
  \pi(z) = \mu_1 \times \theta(\beta'z).
\end{equation*}
Here $\mu_1$ is the maximal marginal probability that can be achieved by the model, since $\theta(.) \leq 1$. It can also be interpreted as the probability of response for $z=z_1$ for which $\theta(\beta'z_1) = 1$ (potentially in limit).

We will allow two options: having $\mu_1$ as a fixed pre-defined constant, or estimating it from the data.


\section{Initial setup}
\begin{flushleft} \small\label{scrap1}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@require(CorrBin)@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\subsection{Exchangeable model}

\begin{equation}\label{E:1to1}
	p_{r,n}= \binom{n}{r} \sum_{j=0}^{n-r} {(-1)^j} \binom{n-r}{j} \lambda_{r+j} = \binom{n}{r} \sum_{s=r}^{n} {(-1)^(s-r)} \binom{n-r}{s-r} \lambda_{s},
\end{equation}

\begin{equation}\label{E:also1to1}
	\lambda_k = \sum_{j=0}^{n-k} \frac{\binom{n-k}{j} {p_{n-j,n}}}{\binom{n}{n-j}} = \sum_{r=k}^{n} \frac{\binom{n-k}{n-r} {p_{r,n}}}{\binom{n}{r}},
\end{equation}


\begin{flushleft} \small\label{scrap2}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@# lambda-to-p weight matrix, rows:r, cols:s@\\
\mbox{}\verb@# (-1)^(s-r)*choose(n,r)*choose(n-r,s-r)@\\
\mbox{}\verb@@\\
\mbox{}\verb@weight_mat <- function(n){@\\
\mbox{}\verb@  s <- r <- 0:n@\\
\mbox{}\verb@  res <- outer(r, s, function(x,y)(-1)^(y-x)*choose(n,x)*choose(n-x,y-x))@\\
\mbox{}\verb@  res@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@\\
\mbox{}\verb@p_from_lambda <- function(lambda.vec, n){@\\
\mbox{}\verb@  H <- weight_mat(n)@\\
\mbox{}\verb@  c(H %*% lambda.vec[1:(n+1)])@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@\\
\mbox{}\verb@# p-to-lambda weight matrix, rows:k, cols:r@\\
\mbox{}\verb@# (choose(n-k, n-r)/choose(n,r)@\\
\mbox{}\verb@@\\
\mbox{}\verb@weight_mat2 <- function(n){@\\
\mbox{}\verb@  k <- r <- 0:n@\\
\mbox{}\verb@  res <- outer(k, r, function(x,y)choose(n-x, n-y)/choose(n,y))@\\
\mbox{}\verb@  res@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@\\
\mbox{}\verb@lambda_from_p <- function(p.vec, n=length(p.vec)-1){@\\
\mbox{}\verb@  H <- weight_mat2(n)@\\
\mbox{}\verb@  c(H %*% p.vec)@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\section{Defining the model}

Parameter estimation is based on the maximization likelihood estimator with respect to likelihood function of observed data. Under the marginal compatibility assumption, the parameters ${\lambda}$ are independent of cluster sizes. The likelihood function based on the observed data is written as follows:
\begin{equation}\label{D:imcompleteL}
	L = {\prod_{i=1}^{I}} f_i\log p_{r_i,n_i}(z_i),
\end{equation}
where $p(r,n)(z)$ is the probability of observing $r$ responses in a cluster of size $n$ given covariates $z$, that can be calculated from \eqref{E:semipara} using the connection between $\lambda$s and probabilities in \eqref{E:1to1}, and $f_i$ are observation weights.


\begin{flushleft} \small\label{scrap3}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@#'@{\tt @}\verb@rdname sprr@\\
\mbox{}\verb@#'@{\tt @}\verb@param formula a one-sided formula of the form \code{cbind(r, s) ~ predictors} where \code{r} and \code{s} give the number of responses and non-responses within each cluster, respectively (so the cluster size is \code{r+s}), and \code{predictors} describes the covariates.@\\
\mbox{}\verb@#'@{\tt @}\verb@param data  an optional matrix or data frame containing the variables in the formula \code{formula}. By default the variables are taken from \code{environment(formula).}@\\
\mbox{}\verb@#'@{\tt @}\verb@param subset  an optional vector specifying a subset of observations to be used.@\\
\mbox{}\verb@#'@{\tt @}\verb@param weight  an optional vector specifying observation weights.@\\
\mbox{}\verb@#'@{\tt @}\verb@param link      a link function for the binomial distribution, the inverse of which models the covariate effects.@\\
\mbox{}\verb@#'@{\tt @}\verb@param mu1       an optional value between 0 and 1 giving the maximal predicted marginal probability. If set to NULL (default), the algorithm will try to estimate it from the data.@\\
\mbox{}\verb@#'@{\tt @}\verb@param start     an optional list with elements named \code{beta}, \code{q}, and/or \code{mu1} giving starting values for estimation. If none or only some are specified, starting values are selected automatically.@\\
\mbox{}\verb@#'@{\tt @}\verb@param control a list with parameters controlling the algorithm.@\\
\mbox{}\verb@#'@{\tt @}\verb@return an object of class \code{sprr} with the fitted model.@\\
\mbox{}\verb@#'@{\tt @}\verb@export@\\
\mbox{}\verb@#' @{\tt @}\verb@importFrom stats terms model.matrix@\\
\mbox{}\verb@@\\
\mbox{}\verb@#' Semi-parametric relative risk model@\\
\mbox{}\verb@sprr <- function(formula, data, subset, weights, link="cloglog", mu1=NULL, start=NULL, control=list(eps=0.001, maxit=100), ...){@\\
\mbox{}\verb@    fam <- binomial(link=link)@\\
\mbox{}\verb@    model_fun <- fam$linkinv@\\
\mbox{}\verb@@\\
\mbox{}\verb@    @\hbox{$\langle\,${\itshape Create model matrix from formula and data}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@    @\hbox{$\langle\,${\itshape Fit model}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@@\\
\mbox{}\verb@    mt <- attr(mf, "terms")@\\
\mbox{}\verb@    res <- list(coefficients = beta_new, q=q_new, niter = iter, loglik=logl,@\\
\mbox{}\verb@                link = link, call = mc, terms = mt,@\\
\mbox{}\verb@                xlevels = .getXlevels(mt, mf),@\\
\mbox{}\verb@                data_object=list(model_matrix=mm, resp=Y, n=rowSums(Y), weights=weights),@\\
\mbox{}\verb@                model_fun=model_fun)@\\
\mbox{}\verb@    class(res) <- "sprr"@\\
\mbox{}\verb@    res@\\
\mbox{}\verb@@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\begin{flushleft} \small\label{scrap4}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape Create model matrix from formula and data}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@   if (missing(formula) || (length(formula) != 3L))@\\
\mbox{}\verb@        stop("'formula' missing or incorrect")@\\
\mbox{}\verb@   if (missing(data))@\\
\mbox{}\verb@        data <- environment(formula)@\\
\mbox{}\verb@    mc <- match.call(expand.dots = FALSE)@\\
\mbox{}\verb@    m <- match(c("formula", "data", "subset", "weights"), names(mc), 0L)@\\
\mbox{}\verb@    m <- mc[c(1L,m)]@\\
\mbox{}\verb@    if (is.matrix(eval(m$data, parent.frame())))@\\
\mbox{}\verb@        m$data <- as.data.frame(data)@\\
\mbox{}\verb@    m[[1L]] <- quote(stats::model.frame)@\\
\mbox{}\verb@    mf <- eval(m, parent.frame())@\\
\mbox{}\verb@@\\
\mbox{}\verb@    # extract and check response variable@\\
\mbox{}\verb@    Y <- model.response(mf)@\\
\mbox{}\verb@    if (ncol(Y) != 2) stop("The response variable should be a 2-column matrix")@\\
\mbox{}\verb@@\\
\mbox{}\verb@    # create model matrix@\\
\mbox{}\verb@    mm <- model.matrix(formula, data=mf)@\\
\mbox{}\verb@@\\
\mbox{}\verb@    # extract weights@\\
\mbox{}\verb@    weights <- as.vector(model.weights(mf))@\\
\mbox{}\verb@    if (!is.null(weights) && !is.numeric(weights))@\\
\mbox{}\verb@        stop("'weights' must be a numeric vector")@\\
\mbox{}\verb@    if (!is.null(weights) && any(weights < 0))@\\
\mbox{}\verb@        stop("negative weights not allowed")@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
Using the model \eqref{E:semipara}, and the 1-to-1 relationship equation \eqref{E:1to1}, for cluster size $N$
\begin{equation}\label{E:Qresp}
\begin{split}
p_{r,N}(z) &= \binom{N}{r} {\sum_{j=0}^{N-r}} {(-1)^j} \binom{N-r}{j} {\mu_{r+j}} {\theta(\beta'z)^{r+j}} \\
      &= \sum_{y=r}^N \binom{y}{r} {\theta(\beta'z)^r} {(1-\theta(\beta'z))}^{y-r} {q_y}.
\end{split}
\end{equation}

Then for other cluster sizes, using marginal compatibility,
\begin{equation*}
p_{r,n}(z) = \sum_{s=0}^{N} h(r,s,n,N)p_{s,N}(z).
\end{equation*}

\subsection{Model predictions and likelihood}
We define internal functions that calculate the model-based predicted values for a set of parameters, and the log-likelihood.

\begin{flushleft} \small\label{scrap5}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@pred_lp <- function(beta, data_object){@\\
\mbox{}\verb@    lp <- data_object$model_matrix %*% beta@\\
\mbox{}\verb@    c(lp)@\\
\mbox{}\verb@}@\\
\mbox{}\verb@pred_theta <- function(beta, data_object, model_fun){@\\
\mbox{}\verb@    lp <- pred_lp(beta, data_object)@\\
\mbox{}\verb@    theta <- model_fun(lp)@\\
\mbox{}\verb@    theta@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@\\
\mbox{}\verb@pred_lambda <- function(beta, q, data_object, model_fun){@\\
\mbox{}\verb@    lp <- data_object$model_matrix %*% beta@\\
\mbox{}\verb@    theta <- model_fun(lp)@\\
\mbox{}\verb@    N <- length(q)-1@\\
\mbox{}\verb@    lambda_N <- lambda_from_p(q)@\\
\mbox{}\verb@    th <- sapply(0:N, function(k)theta^k)@\\
\mbox{}\verb@    lambda <- apply(th, 1, function(t)t * lambda_N)@\\
\mbox{}\verb@    rownames(lambda) <- 0:N@\\
\mbox{}\verb@    t(lambda)@\\
\mbox{}\verb@}@\\
\mbox{}\verb@pred_pvec <- function(beta, q, data_object, model_fun){@\\
\mbox{}\verb@   ll <- pred_lambda(beta, q, data_object, model_fun)@\\
\mbox{}\verb@   cs <- data_object$n@\\
\mbox{}\verb@   pp <- lapply(seq_along(cs), @\\
\mbox{}\verb@                function(i){res <- p_from_lambda(ll[i,], n=cs[i]);@\\
\mbox{}\verb@                            names(res) <- 0:cs[i];@\\
\mbox{}\verb@                            res})@\\
\mbox{}\verb@   pp@\\
\mbox{}\verb@}@\\
\mbox{}\verb@pred_p <- function(beta, q, data_object, model_fun){@\\
\mbox{}\verb@   pvec <- pred_pvec(beta, q, data_object, model_fun)@\\
\mbox{}\verb@   rvec <- data_object$resp[,1]@\\
\mbox{}\verb@   pp <- sapply(seq_along(rvec), function(i)pvec[[i]][rvec[i]+1])@\\
\mbox{}\verb@   pp@\\
\mbox{}\verb@}@\\
\mbox{}\verb@loglik <- function(beta, q, data_object, model_fun){@\\
\mbox{}\verb@    p <- pred_p(beta=beta, q=q, data_object = data_object, model_fun=model_fun)@\\
\mbox{}\verb@    w <- data_object$weights@\\
\mbox{}\verb@    if (is.null(w)) ll <- sum(log(p))@\\
\mbox{}\verb@    else ll <- sum(ifelse(w==0, 0, w*log(p)))@\\
\mbox{}\verb@    ll@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\subsection{Methods for the \texttt{sprr} class}

First, define a printing method which does not show the saved data and model matrix

\begin{flushleft} \small\label{scrap6}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@# based on print.lm@\\
\mbox{}\verb@print.sprr <- function(x, digits = max(3L, getOption("digits") - 3L),...){@\\
\mbox{}\verb@  cat("\nA semi-parametric relative risk regression model fit\n")@\\
\mbox{}\verb@  cat("\nCall:\n", paste(deparse(x$call), sep = "\n", collapse = "\n"),@\\
\mbox{}\verb@        "\n\n", sep = "")@\\
\mbox{}\verb@  if (length(coef(x))) {@\\
\mbox{}\verb@    cat("Coefficients:\n")@\\
\mbox{}\verb@    print.default(format(x$coefficients, digits = digits),@\\
\mbox{}\verb@            print.gap = 2, quote = FALSE)@\\
\mbox{}\verb@    }@\\
\mbox{}\verb@    else cat("No coefficients\n")@\\
\mbox{}\verb@@\\
\mbox{}\verb@    if (length(x$q)){@\\
\mbox{}\verb@        cat("Baseline joint probabilities (mu):\n")     @\\
\mbox{}\verb@        N <- length(x$q)-1@\\
\mbox{}\verb@        ll <- c(lambda_from_p(x$q))@\\
\mbox{}\verb@        names(ll) <- 0:N@\\
\mbox{}\verb@        print.default(format(ll, digits = digits),@\\
\mbox{}\verb@            print.gap = 2, quote = FALSE)@\\
\mbox{}\verb@    }@\\
\mbox{}\verb@    else cat("No baseline joint probabilities\n")@\\
\mbox{}\verb@@\\
\mbox{}\verb@   cat("Log-likelihood: ", format(x$loglik, digits=digits), "\n")@\\
\mbox{}\verb@   invisible(x)@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
The prediction method will predict for a variety of scenarios:
\begin{itemize}
\item Input data set:
  \begin{itemize}
    \item the data used in the fitting;
    \item new data.
  \end{itemize}
\item Results:
  \begin{itemize}
    \item $p_{r,n}(z)$: the probability of observing the given $r$ responses with cluster size $n$, given $z$;
    \item $\{p_{\cdot,n}(z)\}$: the entire vector of response probabilities for cluster size $n$, given $z$ (will be a list due to varying lengths);
    \item $\lambda_{1,n}(z)$: the marginal probability of response for cluster size $n$, given $z$;
    \item $\{\lambda_{\cdot,n}(z)\}$: the entire vector of joint probabilities $\lambda$ for cluster size $n$, given $z$;
    \item $\beta`z$: the linear predictor value $z$;
    \item $\theta(\beta'z)$: the relative risk at predictor value $z$.
  \end{itemize}
\end{itemize}

\begin{flushleft} \small\label{scrap7}\raggedright\small
\NWtarget{nuweb?}{} \verb@"R/SPreg.R"@\nobreak\ {\footnotesize {?}}$\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@predict.sprr <- function(object, newdata=NULL,@\\
\mbox{}\verb@                              type=c("mean", "relrisk", "likelihood", "probvec", "lvec", "lp"),@\\
\mbox{}\verb@                              newn=NULL, ...){@\\
\mbox{}\verb@  type <- match.arg(type)@\\
\mbox{}\verb@  tt <- terms(object)@\\
\mbox{}\verb@  if (!missing(newdata)){    @\\
\mbox{}\verb@    Terms <- delete.response(tt)@\\
\mbox{}\verb@    m <- model.frame(Terms, newdata, xlev = object$xlevels)@\\
\mbox{}\verb@    if (!is.null(cl <- attr(Terms, "dataClasses")))@\\
\mbox{}\verb@            .checkMFClasses(cl, m)@\\
\mbox{}\verb@    mm <- model.matrix(Terms, m)@\\
\mbox{}\verb@    data_object <- list(model_matrix=mm)@\\
\mbox{}\verb@    if (!missing(newn)){@\\
\mbox{}\verb@       if (!(length(newn) == 1L || length(newn) == nrow(newdata)))@\\
\mbox{}\verb@          stop("'newn' should have length 1 or equal to the number of rows of 'newdata'")@\\
\mbox{}\verb@        data_object$n <- rep(newn, length=nrow(newdata))@\\
\mbox{}\verb@       }@\\
\mbox{}\verb@  } else {@\\
\mbox{}\verb@    data_object <- object$data_object@\\
\mbox{}\verb@  }@\\
\mbox{}\verb@  @\\
\mbox{}\verb@@\\
\mbox{}\verb@  if (type=="likelihood"){@\\
\mbox{}\verb@     if (!missing(newdata))@\\
\mbox{}\verb@        stop("Type = 'likelihood' is not available for new data. Consider using type='probvec' to get vector of likelihood values.")@\\
\mbox{}\verb@     pred <- pred_p(beta=object$coefficients, q=object$q,@\\
\mbox{}\verb@                    data_object=data_object,@\\
\mbox{}\verb@                    model_fun=object$model_fun)@\\
\mbox{}\verb@  } else@\\
\mbox{}\verb@  if (type %in% c("mean", "lvec")){@\\
\mbox{}\verb@     ll <- pred_lambda(beta=object$coefficients, q=object$q,@\\
\mbox{}\verb@                    data_object=data_object,@\\
\mbox{}\verb@                    model_fun=object$model_fun)@\\
\mbox{}\verb@     pred <- if (type=="mean") ll[,2] else ll           @\\
\mbox{}\verb@  } else@\\
\mbox{}\verb@  if (type == "lp"){@\\
\mbox{}\verb@     pred <- pred_lp(beta=object$coefficients, data_object=data_object)@\\
\mbox{}\verb@  } else@\\
\mbox{}\verb@  if (type == "relrisk"){@\\
\mbox{}\verb@     pred <- pred_theta(beta=object$coefficients, data_object=data_object,@\\
\mbox{}\verb@                        model_fun=object$model_fun)@\\
\mbox{}\verb@  }@\\
\mbox{}\verb@  if (type == "probvec"){@\\
\mbox{}\verb@    if (!missing(newdata) && missing(newn))@\\
\mbox{}\verb@       stop("For prediction of probability vectors with new data, cluster sizes should be specified in 'newn'")@\\
\mbox{}\verb@    pred <- pred_pvec(beta=object$coefficients, q=object$q, data_object=data_object,@\\
\mbox{}\verb@                        model_fun=object$model_fun) @\\
\mbox{}\verb@  }@\\
\mbox{}\verb@  return(pred)    @\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtFileDefBy\ \NWlink{nuweb?}{?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}\NWlink{nuweb?}{, ?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\section{Fitting the model via an EM-MM algorithm}

We implement an algorithm called the Expectation Maximization Minorize-Maximize, abbreviated as EM MM, to estimate parameters.  Catalina Stefanescu and Bruce W. Turnbull have proved that the marginal compatibility assumption is equivalent to assuming that clusters are from a sample of clusters sharing the same cluster size (the maximum cluster size $N$ is a good choice and is used in our study), but some observations are completely missing at random, abbreviated as MCAR \cite{stefanescu2003likelihood}. The expectation step in the EM MM algorithm can be performed based on the MCAR assumption. The estimation of the non-parametric backbone $\mu_k$ will be done through the corresponding pdf $q_t, t=0,\ldots,N$, because enforcing the complete monotonicity of $\mu$ is much more demanding than enforcing $\sum q_t=1$. Thus the set of parameters to be estimated is $\phi = (q, \beta)$, under the restrictions $\sum_{y=0}^N q_y=1$ and $\frac 1N \sum_{y=0}^{N}yq_y=\mu_1$.

In the EM setup, the missing data for each cluster $i$ comes from its representation as a MCAR sample from a cluster of size $N$ with $s_i$ responses. So the complete data are $\mathcal{D}=\{r_i, n_i, z_i; s_i)\}_{i=1}^I$ and the observed data are $\mathcal{D}=\{r_i, n_i, z_i; s_i)\}_{i=1}^I$. The complete data log-likelihood is
\begin{equation*}
  \log L_c (\phi \mid \mathcal{D}_c) = \sum_{i=1}^I f_i \log p_{s_i}(z_i) = \sum_{i=1}^I \sum_{s=0}^N f_i I(s_i=s) \log \Big[ \sum_{y=s}^N \binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}\Big].
\end{equation*}
Its expectation given the observed data and a current set of parameter estimates $\phi^{(k)}$ is
\begin{equation*}
  E[\log L_c \mid \phi^{(k)}, \mathcal{D}]  = \sum_{i=1}^I \sum_{s=0}^N f_i P(S_i=s \mid \phi^{(k)}, \mathcal{D}) \log  \Big[\sum_{y=s}^N \binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}\Big].
\end{equation*}



\begin{flushleft} \small\label{scrap8}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape Fit model}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@    @\hbox{$\langle\,${\itshape Define internal functions}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@    @\hbox{$\langle\,${\itshape Set initial values}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@@\\
\mbox{}\verb@    @\hbox{$\langle\,${\itshape Setup for E-step}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@    iter <- 0@\\
\mbox{}\verb@    diff <- 100@\\
\mbox{}\verb@    while ((diff > control$eps) & (iter < control$maxit)){@\\
\mbox{}\verb@        iter <- iter + 1@\\
\mbox{}\verb@        beta_old <- beta_new@\\
\mbox{}\verb@        q_old <- q_new@\\
\mbox{}\verb@@\\
\mbox{}\verb@        @\hbox{$\langle\,${\itshape E-step}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@        @\hbox{$\langle\,${\itshape M-step for beta}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@        @\hbox{$\langle\,${\itshape M-step for q}\nobreak\ {\footnotesize \NWlink{nuweb?}{?}}$\,\rangle$}\verb@@\\
\mbox{}\verb@@\\
\mbox{}\verb@        diff <- sum(abs(beta_old - beta_new)) + sum(abs(q_old - q_new))@\\
\mbox{}\verb@    }@\\
\mbox{}\verb@    logl <- loglik(beta_new, q_new, list(model_matrix=mm, resp=Y, n=rowSums(Y), weights=weights), model_fun=model_fun)@\\
\mbox{}\verb@    names(beta_new) <- colnames(mm)@\\
\mbox{}\verb@@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\subsection{E-step}
Using the Bayes theorem,
\begin{equation*}
  e_{is}^{(k)} = P(s_i=s \mid \phi^{(k)}, \mathcal{D}) \propto h(r_i, s, n_i, N) P(S_i=s \mid \phi^{(k)}, \mathcal{D}),
\end{equation*}
where the coefficient of proportionality is chosen so that these values add up to 1 over $s=0,\ldots, N$, and
\begin{equation*}
   P(S_i=s \mid \phi^{(k)}, \mathcal{D}) = \sum_{y=s}^N \binom{y}{s} \theta(\beta^{(k)'}z_i)^s (1-\theta(\beta^{(k)'}z_i))^{y-s} q^{(k)}_y.
\end{equation*}


\subsection{M-step}

The maximization step uses Minorize-Maximize to update the parameters $\phi$. We apply Jensen's inequality to bound from below the sum within the logarithm by assigning element-wise weights to each $q_{y}$, and transforming the log sum expression to obtain an update for parameters $\phi$.

\begin{multline*}
\log \Big[\sum_{y=s}^N \binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}\Big] =
\log \Big[\sum_{y=s}^N w_{iys}^{(k)} \frac{\binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}}{w_{iys}^{(k)}}\Big] \geq \\
\sum_{y=s}^N w_{iys}^{(k)} \log\Big[\frac{\binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}}{w_{iys}^{(k)}}\Big] = \\
\sum_{y=s}^N w_{iys}^{(k)} \log\Big[\binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} {q_y}\Big] -\sum_{y=s}^N w_{iys}^{(k)} \log w_{iys}^{(k)}.
\end{multline*}


Therefore, the lower bound of the expected complete data log-likelihood function is:
\begin{multline}\label{E:LowerBound}
	 E[\log L_c(\phi) \mid \phi^{(k)}, \mathcal{D}] \geq  \\
 \sum_{i=1}^I \sum_{s=0}^N \sum_{y=s}^N f_i e_{is}^{(k)} w_{iys}^{(k)} \log\Big[\binom{y}{s} {\theta(\beta'z_i)^s} {(1-\theta(\beta'z_i))}^{y-s} \Big] +
  \sum_{i=1}^I \sum_{s=0}^N \sum_{y=s}^N f_i e_{is}^{(k)} w_{iys}^{(k)} \log{q_y} -\\
 \sum_{i=1}^I \sum_{s=0}^N \sum_{y=s}^N f_i e_{is}^{(k)} w_{iys}^{(k)}\log w_{iys}^{(k)} ,
\end{multline}
where the last term does not actually depend on the parameters, and can be ignored. Also note that the terms containing $\beta$ and $q$ are separated, and can be maximized individually.

The weights at the $k^{th}$ iteration are selected so that they add up to 1 and in the above equation equality holds for $\phi=\phi^{(k)}$,
\begin{equation}\label{D:weights}
	w_{iys}^{(k)} = \frac{\binom{y}{s} {\theta(\beta^{(k)'}z_i)^s} {(1-\theta(\beta^{(k)'}z_i))}^{y-s} {q^{(k)}_y} }%
                          {\sum_{\gamma=s}^N \binom{\gamma}{s} {\theta(\beta^{(k)'}z_i)^s} {(1-\theta(\beta^{(k)'}z_i))}^{\gamma-s} {q^{(k)}_\gamma}}.
\end{equation}

\subsection{Implementation of E-step}

In \eqref{E:LowerBound} we only need
$$e_{is}^{(k)}w_{iys}^{(k)} = \frac{ f_i h(r_i, s, n_i, N) a_{iys}^{(k)}}{\sum_{t=0}^{N}\sum_{\gamma=t}^{N} h(r_i, t, n_i, N) a_{i\gamma t}^{(k)}},$$
where $a_{iys}^{(k)} = \binom{y}{s} {\theta(\beta^{(k)'}z_i)^s} {(1-\theta(\beta^{(k)'}z_i))}^{y-s} {q^{(k)}_y}$ and the denominator is just a normalizing constant.

\begin{flushleft} \small\label{scrap9}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape Setup for E-step}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@    # replace each cluster with N(N-1)/2 clusters of size N@\\
\mbox{}\verb@    new <- cbind(s=rep(0:N, each=N+1), y=rep(0:N, times=N+1))@\\
\mbox{}\verb@    new <- new[new[,"s"] <= new[,"y"],]@\\
\mbox{}\verb@@\\
\mbox{}\verb@    rep_idx <- rep(1:nrow(Y), each=nrow(new))@\\
\mbox{}\verb@    Y2 <- cbind(1:nrow(Y), Y)[rep_idx,]@\\
\mbox{}\verb@    colnames(Y2) <- c("i", "resp","nonresp")@\\
\mbox{}\verb@    mm2 <- mm[rep_idx,,drop=FALSE]@\\
\mbox{}\verb@@\\
\mbox{}\verb@    rep_idx2 <- rep(1:nrow(new), times=nrow(Y))@\\
\mbox{}\verb@    Ycomb <- cbind(Y2, new[rep_idx2,])@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\begin{flushleft} \small\label{scrap10}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape E-step}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@    # calculate a_{iys}^k@\\
\mbox{}\verb@    lp <- mm2 %*% beta_old@\\
\mbox{}\verb@    theta <- model_fun(lp)@\\
\mbox{}\verb@    a <- dbinom(x=Ycomb[,"s"], size=Ycomb[,"y"], prob=theta) * q_old[Ycomb[,"y"]+1]@\\
\mbox{}\verb@@\\
\mbox{}\verb@    # calculate e_{is}^k w_{iys}^k@\\
\mbox{}\verb@    ew_num <- dhyper(x=Ycomb[,"resp"], m=Ycomb[,"s"], n=N - Ycomb[,"s"],@\\
\mbox{}\verb@                     k=Ycomb[,"resp"] + Ycomb[,"nonresp"]) * a@\\
\mbox{}\verb@    ew_denom <- tapply(ew_num, list(i=Ycomb[,"i"]), sum, simplify=TRUE)@\\
\mbox{}\verb@    ew <-  ew_num / ew_denom[Ycomb[,"i"]]@\\
\mbox{}\verb@    if (!is.null(weights)) ew <- weights * ew@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\subsection{Implementation of the M-step}

The first term in \eqref{E:LowerBound} corresponds to a weighted binomial likelihood with $y$ as the cluster size, $s$ as the number of successes, a link function $\theta^{-1}$, and weights $f_i e_{is}^{(k)}w_{iys}^{(k)}$, so $\beta$ can be updated using logistic regression.

\begin{flushleft} \small\label{scrap11}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape M-step for beta}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@    mod <- glm(cbind(Ycomb[,"s"], Ycomb[,"y"]-Ycomb[,"s"]) ~ mm2+0, family=fam, weights=ew, start=beta_old)@\\
\mbox{}\verb@    beta_new <- coef(mod)@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
The second term is a multinomial likelihood for $q$ with the usual restriction  $\sum_{y=0}^N q_y=1$, and an additional restriction for the mean $\sum_{y=0}^{N}yq_y=N \mu_1$. Rewriting the second term of \eqref{E:LowerBound} with $c^{(k)}_y = \sum_{i=1}^I \sum_{s=0}^N f_i e_{is}^{(k)} w_{iys}^{(k)}$ and including the equality constraints via a Lagrangian, we need to maximize
\begin{equation*}
  F(q,\alpha_1,\alpha_2) = \sum_{y=0}^{N}c^{(k)}_y\log q_y - \alpha_1 (\sum_{y=0}^{N}q_y - 1) - \alpha_2 (\sum_{y=0}^{N}yq_y - N\mu_1).
\end{equation*}
Taking partial derivatives, and setting them to 0, we can show that the solution is
\begin{equation}\label{E:q_update}
  q^{(k)}_y = \frac{c^{(k)}_y}{1+r y} \Big/ \Big[ \sum_{x=0}^{N}\frac{c^{(k)}_x}{1+r x}\Big],
\end{equation}
where $r=\hat\alpha_2 / \hat\alpha_2$ is the solution of the equation
\begin{equation}\label{E:r_equation}
   f(r) = \sum_{x=0}^{N}\frac{c^{(k)}_x (x - N\mu_1)}{1+r x} = 0.
\end{equation}
To ensure $q_y\geq 0$ for all $y=0,\ldots,N$, we need $r> -\frac 1N$. We reparameterize it as $r=-\frac 1N+\exp(\rho)$ to enforce the constraint.

\begin{flushleft} \small\label{scrap12}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape Define internal functions}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@mean_constrained_probs <- function(cc, m=NULL){@\\
\mbox{}\verb@    if (is.null(m)) return(cc/sum(cc))          @\\
\mbox{}\verb@    N <- length(cc) - 1@\\
\mbox{}\verb@    r_eq <- Vectorize(function(rho){i <- 0:N; sum(cc * (i - m)/(1+(exp(rho)-1/N)*i))})@\\
\mbox{}\verb@    rho <- uniroot(r_eq, interval=c(-10, 10), extendInt="yes")@\\
\mbox{}\verb@    r <- exp(rho$root) - 1/N@\\
\mbox{}\verb@    q <- cc / (1 + r * (0:N))@\\
\mbox{}\verb@    q <- q/sum(q)@\\
\mbox{}\verb@    q@\\
\mbox{}\verb@}@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\begin{flushleft} \small\label{scrap13}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape M-step for q}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@    c_vec <- tapply(ew, list(y=Ycomb[,"y"]), sum, simplify=TRUE)@\\
\mbox{}\verb@    if (is.null(mu1))@\\
\mbox{}\verb@       q_new <- mean_constrained_probs(c_vec)@\\
\mbox{}\verb@    else@\\
\mbox{}\verb@       q_new <- mean_constrained_probs(c_vec, N*mu1)@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\subsection{Initial values}

The initial values for $\beta$ can be selected using linear regression on transformed estimates of the marginal probabilities:
\begin{equation*}
  \theta^{-1}\Big(\frac{\pi(z)}{\mu_1}\Big) = \beta'z
\end{equation*}
%
%For $q$, we need to ensure that it gives a marginal probability of $\mu_1$. We will use a mixture of the discrete uniform distribution on $0,\ldots,N$ to ensure that no probabilities %are zero, and a point mass at either $0$ or $N$, depending on whether $\mu_1$ is below or over 0.5.

For $q$, we will get the marginally compatible estimate for the pooled dataset, ensure a minimal probability of 0.01 at each value, then shift it to have mean $\mu_1$.

\begin{flushleft} \small\label{scrap14}\raggedright\small
\NWtarget{nuweb?}{} $\langle\,${\itshape Set initial values}\nobreak\ {\footnotesize {?}}$\,\rangle\equiv$
\vspace{-1ex}
\begin{list}{}{} \item
\mbox{}\verb@@\\
\mbox{}\verb@ N <- max(rowSums(Y))@\\
\mbox{}\verb@@\\
\mbox{}\verb@ if (is.null(start$beta)){   @\\
\mbox{}\verb@    p0 <- (Y[,1] + 0.5)/(Y[,1] + Y[,2]+ 1)@\\
\mbox{}\verb@    if (is.null(mu1) && is.null(start$mu1))@\\
\mbox{}\verb@       lp0 <- fam$linkfun(pmin(1-.Machine$double.eps, p0))@\\
\mbox{}\verb@    else if (!is.null(mu1))@\\
\mbox{}\verb@       lp0 <- fam$linkfun(pmin(1-.Machine$double.eps, p0/mu1))@\\
\mbox{}\verb@    else if (!is.null(start$mu1))@\\
\mbox{}\verb@       lp0 <- fam$linkfun(pmin(1-.Machine$double.eps, p0/start$mu1))@\\
\mbox{}\verb@    if (is.null(weights))       @\\
\mbox{}\verb@        lm0 <- lm.fit(x=mm, y=lp0)@\\
\mbox{}\verb@    else         @\\
\mbox{}\verb@        lm0 <- lm.wfit(x=mm, y=lp0, w=weights)@\\
\mbox{}\verb@    beta_new <- coef(lm0)@\\
\mbox{}\verb@ } else {@\\
\mbox{}\verb@    beta_new <- start$beta@\\
\mbox{}\verb@ }@\\
\mbox{}\verb@ @\\
\mbox{}\verb@ if (is.null(start$q)){@\\
\mbox{}\verb@    pooled <- CBData(data.frame(Trt = "All", NResp = Y[,1], ClusterSize = rowSums(Y)), trt="Trt",@\\
\mbox{}\verb@                     clustersize="ClusterSize", nresp="NResp")@\\
\mbox{}\verb@    est <- mc.est(pooled)@\\
\mbox{}\verb@    q0 <- est$Prob[est$ClusterSize == N]@\\
\mbox{}\verb@    if (is.null(mu1) && is.null(start$mu1))@\\
\mbox{}\verb@        q_new <- mean_constrained_probs(pmax(q0, 0.01))@\\
\mbox{}\verb@     else if (!is.null(mu1))@\\
\mbox{}\verb@        q_new <- mean_constrained_probs(pmax(q0, 0.01), N*mu1)@\\
\mbox{}\verb@     else if (!is.null(start$mu1))@\\
\mbox{}\verb@        q_new <- mean_constrained_probs(pmax(q0, 0.01), N*start$mu1)@\\
\mbox{}\verb@ } else {@\\
\mbox{}\verb@   q_new <- start$q@\\
\mbox{}\verb@   if (!is.null(start$mu1))@\\
\mbox{}\verb@      q_new <- mean_constrained_probs(q_new, N*start$mu1)@\\
\mbox{}\verb@  }@\\
\mbox{}\verb@@{\NWsep}
\end{list}
\vspace{-1.5ex}
\footnotesize
\begin{list}{}{\setlength{\itemsep}{-\parsep}\setlength{\itemindent}{-\leftmargin}}
\item \NWtxtMacroRefIn\ \NWlink{nuweb?}{?}.

\item{}
\end{list}
\vspace{4ex}
\end{flushleft}
\end{document} 
